{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Deep Computer Vision Using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the solution for the exercises 9, 10 and 11 of the chapter 14: *Deep Computer Vision Using Convolutional Neural Networks* of the book *Hands On Machine Learning with Scikit-Learn, Keras & TensorFlow* of Aurélien Géron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import (\n",
    "    models,\n",
    "    layers, \n",
    "    optimizers, \n",
    "    callbacks,\n",
    "    activations,\n",
    "    datasets, \n",
    "    applications,\n",
    "    metrics\n",
    ")\n",
    "from tensorflow.train import Example, Features, Feature, BytesList, Int64List, FloatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-553480e19e43f1c2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-553480e19e43f1c2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join('../../data', 'processed', 'mnist')\n",
    "LOGS_PATH = os.path.join('../../reports', 'logs', 'mnist')\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Logging configuration\n",
    "logging_format = '%(message)s'\n",
    "logging.basicConfig(format=logging_format, level=logging.INFO)\n",
    "\n",
    "# Launch the TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=../../reports/logs/mnist --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and Save the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data():\n",
    "    mnist = datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_valid = x_train[:50000], x_train[50000:]\n",
    "    y_train, y_valid = y_train[:50000], y_train[50000:]\n",
    "    \n",
    "    train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    valid_set = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    \n",
    "    logging.info('The dataset has been fetched.')\n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "def save_tfrecord(image, label):\n",
    "    \n",
    "    image = tf.io.serialize_tensor(image).numpy()\n",
    "    label = label.numpy()\n",
    "    \n",
    "    image_example = Example(\n",
    "        features = Features(\n",
    "            feature = {\n",
    "                'image' : Feature(bytes_list=BytesList(value=[image])),\n",
    "                'label' : Feature(int64_list=Int64List(value=[label]))\n",
    "    })).SerializeToString()\n",
    "    \n",
    "    return image_example\n",
    "\n",
    "def save_datasets(n_files=15):\n",
    "    \n",
    "    train_set, valid_set, test_set = fetch_data()\n",
    "    datasets = [train_set, valid_set, test_set]\n",
    "    \n",
    "    data_types = ['train', 'valid', 'test']\n",
    "    for data_type in data_types:\n",
    "        data_path = os.path.join(DATA_PATH, data_type)\n",
    "        os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "    train_paths = [os.path.join(DATA_PATH,'train', f'train_{number_file}.tfrecord') for number_file in range(n_files)]\n",
    "    valid_paths = [os.path.join(DATA_PATH, 'valid', f'valid_{number_file}.tfrecord') for number_file in range(n_files)]\n",
    "    test_paths = [os.path.join(DATA_PATH, 'test', f'test_{number_file}.tfrecord') for number_file in range(n_files)]\n",
    "    filepaths = [train_paths, valid_paths, test_paths]\n",
    "    \n",
    "    for filepath, dataset in zip(filepaths, datasets):\n",
    "        writers = [tf.io.TFRecordWriter(path) for path in filepath]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            n_file = index % n_files\n",
    "            example = save_tfrecord(image, label)\n",
    "            writers[n_file].write(example)\n",
    "        logging.info(f'The {data_type} dataset has been saved as TFRecord files.')\n",
    "    \n",
    "    return train_paths, valid_paths, test_paths\n",
    "\n",
    "def get_filepaths():\n",
    "    \n",
    "    if os.path.exists(DATA_PATH):\n",
    "        data_types = ['train', 'valid', 'test']\n",
    "        filepaths = []\n",
    "        for data_type in data_types:\n",
    "            list_files = os.listdir(os.path.join(DATA_PATH, data_type))\n",
    "            filepath = [os.path.join(DATA_PATH, data_type, file) for file in list_files]\n",
    "            filepaths.append(filepath)\n",
    "        \n",
    "        train_paths = filepaths[0]\n",
    "        valid_paths = filepaths[1]\n",
    "        test_paths = filepaths[2]\n",
    "        \n",
    "    else:\n",
    "        train_paths, valid_paths, test_paths = save_datasets()\n",
    "    \n",
    "    logging.info('The paths for the files of the dataset have been retrieved.')\n",
    "    \n",
    "    return train_paths, valid_paths, test_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(serialized_image):\n",
    "    feature_descriptions = {\n",
    "        'image' : tf.io.FixedLenFeature([], tf.string, default_value=b''),\n",
    "        'label' : tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_image,\n",
    "                                         feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example['image'], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=(28, 28, 1))\n",
    "    return image, example['label']\n",
    "\n",
    "def get_data(filepaths, shuffle_buffer_size=None, batch_size=32):\n",
    "    list_files = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = tf.data.TFRecordDataset(list_files, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE).cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    \n",
    "    return dataset.batch(batch_size, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConvLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, n_filters, size_filters=3, strides=2, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_filters = n_filters\n",
    "        self.size_filters = size_filters\n",
    "        self.strides = strides\n",
    "        self.activation = activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            layers.Conv2D(n_filters, size_filters, strides=strides, padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            layers.Conv2D(n_filters, size_filters, strides=1, padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "        ]\n",
    "        self.skip_layers = [\n",
    "            layers.Conv2D(n_filters, 1, strides=strides, padding='same', use_bias=False),\n",
    "            layers.BatchNormalization()\n",
    "        ]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            z = layer(z)\n",
    "        skip_z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_z = layer(skip_z)\n",
    "        \n",
    "        return self.activation(z + skip_z)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config =  super().get_config()\n",
    "        config.update({\n",
    "            'n_filters' : self.n_filters,\n",
    "            'size_filters' : self.size_filters,\n",
    "            'strides' : self.strides,\n",
    "            'activation' : self.activation,\n",
    "            'main_layers' : self.main_layers,\n",
    "            'skip_layers' : self.skip_layers\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(train_set):\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(15)\n",
    "    \n",
    "    normalizer = layers.Normalization(input_shape=[28, 28, 1])\n",
    "    sample_data = train_set.take(1000).map(lambda x, y: x)\n",
    "    normalizer.adapt(sample_data)\n",
    "        \n",
    "    model = models.Sequential([\n",
    "        normalizer,\n",
    "        layers.Conv2D(64, 5, padding='same', activation='relu', input_shape=[28, 28, 1]),\n",
    "        layers.BatchNormalization(),\n",
    "        CustomConvLayer(128),\n",
    "        CustomConvLayer(256),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    logging.info('The model has been created.')\n",
    "    \n",
    "    optimizer = optimizers.Nadam()\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    logging.info('The model has been compiled.')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_set, valid_set, test_set):\n",
    "    \n",
    "    early_stopping_cb = callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "    tensorboard_cb = callbacks.TensorBoard(log_dir=LOGS_PATH)\n",
    "    \n",
    "    callbacks_list = [early_stopping_cb, tensorboard_cb]\n",
    "    \n",
    "    logging.info('Training the model...')\n",
    "    \n",
    "    model.fit(train_set,\n",
    "                validation_data=valid_set,\n",
    "                epochs=500,\n",
    "                callbacks=callbacks_list)\n",
    "    \n",
    "    logging.info('The model has been trained')\n",
    "    \n",
    "    accuracy_model = round(model.evaluate(test_set, verbose=0)[1], 6) * 100\n",
    "    logging.info(f'The accuracy of the model is {accuracy_model}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The paths for the files of the dataset have been retrieved.\n",
      "2022-02-28 14:07:18.325548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-28 14:07:18.343197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-28 14:07:20.646844: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "The model has been created.\n",
      "The model has been compiled.\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 14:07:22.262180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1563/Unknown - 47s 29ms/step - loss: 0.2999 - accuracy: 0.9161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 14:08:08.991847: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 51s 31ms/step - loss: 0.2999 - accuracy: 0.9161 - val_loss: 0.1046 - val_accuracy: 0.9760\n",
      "Epoch 2/500\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.0912 - accuracy: 0.9761 - val_loss: 0.0599 - val_accuracy: 0.9841\n",
      "Epoch 3/500\n",
      " 723/1563 [============>.................] - ETA: 24s - loss: 0.0660 - accuracy: 0.9818"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [141]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m test_set \u001b[39m=\u001b[39m get_data(test_filepaths)\n\u001b[1;32m      7\u001b[0m model \u001b[39m=\u001b[39m new_model(train_set)\n\u001b[0;32m----> 8\u001b[0m train_model(model, train_set, valid_set, test_set)\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "Input \u001b[0;32mIn [140]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_set, valid_set, test_set)\u001b[0m\n\u001b[1;32m     42\u001b[0m callbacks_list \u001b[39m=\u001b[39m [early_stopping_cb, tensorboard_cb]\n\u001b[1;32m     44\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mTraining the model...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_set,\n\u001b[1;32m     47\u001b[0m             validation_data\u001b[39m=\u001b[39;49mvalid_set,\n\u001b[1;32m     48\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m     49\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks_list)\n\u001b[1;32m     51\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mThe model has been trained\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m accuracy_model \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(model\u001b[39m.\u001b[39mevaluate(test_set, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)[\u001b[39m1\u001b[39m], \u001b[39m6\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_filepaths, valid_filepaths, test_filepaths = get_filepaths()\n",
    "    train_set = get_data(train_filepaths, shuffle_buffer_size=10000)\n",
    "    valid_set = get_data(valid_filepaths)\n",
    "    test_set = get_data(test_filepaths)\n",
    "    \n",
    "    model = new_model(train_set)\n",
    "    train_model(model, train_set, valid_set, test_set)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11:\n",
    "\n",
    "**Go through TensorFlow’s Style Transfer tutorial. It is a fun way to generate art\n",
    "using Deep Learning.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6ba1b7cf6e8418139948d4f5b35e26443252c5696a8a4a7bc6c27d254786872"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('books-zhEizXov-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
