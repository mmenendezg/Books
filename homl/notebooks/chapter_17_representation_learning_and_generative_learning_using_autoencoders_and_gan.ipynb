{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import (\n","    datasets,\n","    layers,\n","    Sequential,\n","    optimizers,\n","    activations\n",")"]},{"cell_type":"markdown","metadata":{"id":"LHmiVh79FD0B"},"source":["# Exercises"]},{"cell_type":"markdown","metadata":{},"source":["### 1. What are the main tasks that autoencoders are used for?"]},{"cell_type":"markdown","metadata":{},"source":["The autoencoders are used in a wide variety of problems, the most common problems are:\n","\n","- Data visualization\n","- Denoising images\n","- Unsupervised Pretraining\n","- Feature extraction\n","- Anomaly detection"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Suppose you want to train a classifier, and you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?"]},{"cell_type":"markdown","metadata":{},"source":["We can use a deep autoencoder to extract the main features of the unlabeled data. We can then reuse the low layers of the encoder to train a clasification model with the labeled data. The reused layers will be trainable, unless the labeled data is so little. "]},{"cell_type":"markdown","metadata":{},"source":["### 3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder? How can you evaluate the performance of an autoencoder?"]},{"cell_type":"markdown","metadata":{},"source":["Since the autoencoder copies the input to the output, is possible that the model is overfitting. One way to evaluate the model is by measuring the reconstruction loss (i.e., MSE), or by measuring the performance of the classifier if we are performing unsupervised pretraining."]},{"cell_type":"markdown","metadata":{},"source":["### 4. What are undercomplete and overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?"]},{"cell_type":"markdown","metadata":{},"source":["In an undercomplete autoencoder, the codings are smaller than the input, whereas in an overcomplete autoencoder, the codings are bigger than the inputs. The main risk for the first is that the decoder might not be able to reconstruct the input. In the case of the latter, the main risk is that the autoencoder learns \"by heart\" to reconstruct the input, without actually learning any important feature in the process."]},{"cell_type":"markdown","metadata":{},"source":["### 5. How do you tie weights in a stacked autoencoder? What is the point of doing so?"]},{"cell_type":"markdown","metadata":{},"source":["Tying weights is possible when the encoder and the decoder are symmetric. In this case, the weights of the layers of the encoder are copied to the reverse operation layers of the decoder. This speeds up the training by reducing the number of parameters, and decreases the overfitting."]},{"cell_type":"markdown","metadata":{},"source":["### 6. What is a generative model? Can you name a type of generative autoencoder?"]},{"cell_type":"markdown","metadata":{},"source":["A generative model is an autoencoder that is able to generate new outputs when random noise is supplied as input. One example of this is the *Variational Autoencoder (VAE)*."]},{"cell_type":"markdown","metadata":{},"source":["### 7. What is a GAN? Can you name a few tasks where GANs can shine?"]},{"cell_type":"markdown","metadata":{},"source":["A GAN is a generative model composed by two subnetworks: a generative network and a discriminatory network. This two subnetworks are trained to overcome each other: the discrimatory network is trained to tell a real (training data) image from a fake one(generated image), while the generative network is trained to generate images that defeat the discriminatory network. \n","\n","When training the gan, the generative network learns from the experience of the discriminatory network, and it only uses the gradients of the latter one, it never actually \"sees\" any real image to compare to. \n","\n","Some of the tasks where the GANs shine are:\n","\n","- Colorization\n","- Image editing (by substituting parts of the image)\n","- Increase resolution\n","- Increase the frame rate of a video (by interpolating images between 2 frames)\n","- Data augmentation"]},{"cell_type":"markdown","metadata":{},"source":["### 8. What are the main difficulties when training GANs?"]},{"cell_type":"markdown","metadata":{},"source":["Training GANs can be really challenging. The *mode collapse* is one great example: the generator may start producing images of some classes while ignoring other classes, thus reducing the diversity of the images supplied to the discriminator. The GANs are also prone to have unstable training. Finally, the GANs are very sensitive to the hyperparameters."]},{"cell_type":"markdown","metadata":{},"source":["### 9. Try using a denoising autoencoder to pretrain an image classifier. You can use MNIST (the simplest option), or a more complex image dataset such as CIFAR10 if you want a bigger challenge. Regardless of the dataset youâ€™re using, follow these steps:\n","> The dataset to be used is the CIFAR100\n","\n","### - Split the dataset into a training set and a test set. Train a deep denoising autoencoder on the full training set."]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# We will use the CIFAR100 to solve this exercise\n","(x_train, _), (x_test, _) = datasets.cifar100.load_data()"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def preprocessing(tensor):\n","    max_value = np.max(tensor)\n","    tf_tensor = tf.data.Dataset.from_tensors(tensor / 255).batch()\n","    print(tf_tensor)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<TensorDataset element_spec=TensorSpec(shape=(50000, 32, 32, 3), dtype=tf.float64, name=None)>\n"]}],"source":["preprocessing(x_train)"]},{"cell_type":"markdown","metadata":{},"source":["The size of the images is 32x32. We will reduce the size of the image to a latent vector of size 30"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder = Sequential([\n","    layers.Flatten(input_shape=[32, 32]),\n","    layers.GaussianNoise(),\n","    layers.Dense(\n","        512,\n","        activation='elu',\n","        kernel_initializer='he_normal'\n","    )\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### - Check that the images are fairly well reconstructed. Visualize the images that most activate each neuron in the coding layer."]},{"cell_type":"markdown","metadata":{},"source":["### - Build a classification DNN, reusing the lower layers of the autoencoder. Train it using only 500 images from the training set. Does it perform better with or without pretraining?"]},{"cell_type":"markdown","metadata":{},"source":["### 10. Train a variational autoencoder on the image dataset of your choice, and use it to generate images. Alternatively, you can try to find an unlabeled dataset that you are interested in and see if you can generate new samples."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### 11. Train a DCGAN to tackle the image dataset of your choice, and use it to generate images. Add experience replay and see if this helps. Turn it into a conditional GAN where you can control the generated class."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOcaHVHOqKp3mOrZcvy7D8L","collapsed_sections":[],"name":"chapter_17_representation_learning_and_generative_learning_using_autoencoders_and_gan.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.5 ('.venv': poetry)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"b20fb8559386147dc77cba9f7518a8c175fc982b8c10bebe842520e16b3ac5d9"}}},"nbformat":4,"nbformat_minor":0}
