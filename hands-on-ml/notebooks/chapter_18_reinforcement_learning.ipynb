{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chapter_18_reinforcement_learning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOxZeFlIKCR93BOp9EoxNJp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"XRKrknKgFxn1"}},{"cell_type":"markdown","source":["# Learning to Optimize Rewards"],"metadata":{"id":"2Tljlj5WFxiU"}},{"cell_type":"markdown","source":["# Policy Search"],"metadata":{"id":"Z6MNjorWFxcs"}},{"cell_type":"markdown","source":["# Introduction to OpenIA Gym"],"metadata":{"id":"ctS-v9LaFxWt"}},{"cell_type":"markdown","source":["# Neural Network Policies"],"metadata":{"id":"2KAH85rQFxQ9"}},{"cell_type":"markdown","source":["# Evaluating Actions: The Credit Assignment Problem"],"metadata":{"id":"0f7TJ9_9FxJ9"}},{"cell_type":"markdown","source":["# Policy Gradients"],"metadata":{"id":"aVEgrwQnFxEU"}},{"cell_type":"markdown","source":["# Markov Decision Processes"],"metadata":{"id":"4n48xtUzFw9u"}},{"cell_type":"markdown","source":["# Temporal Difference Learning"],"metadata":{"id":"tK9SK3urFw4c"}},{"cell_type":"markdown","source":["# Q-Learning"],"metadata":{"id":"I20a3j7MFwyt"}},{"cell_type":"markdown","source":["# Implementing Q-Learning"],"metadata":{"id":"43t5IeWKGk6v"}},{"cell_type":"markdown","source":["# Deep Q-Learning Variants"],"metadata":{"id":"LX4GhmjpGkyX"}},{"cell_type":"markdown","source":["# The TF-Agents Library"],"metadata":{"id":"6-pzWIL6Fws9"}},{"cell_type":"markdown","source":["# Overview of Some Popular RL Algorithms"],"metadata":{"id":"0z-kdN5wFwnM"}},{"cell_type":"markdown","source":["# Exercises"],"metadata":{"id":"SqDox7UWFwhU"}}]}