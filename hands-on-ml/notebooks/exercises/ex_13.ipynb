{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers, optimizers, losses, callbacks, metrics\n",
    "from tensorflow.train import BytesList, FloatList, Int64List, Feature, Features, Example\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13: Loading and Preprocessing Data with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the solution for the exercises 9 and 10 of the chapter 13: *Loading and Preprocessing Data with TensorFlow* of the book *Hands On Machine Learning with Scikit-Learn, Keras & TensorFlow* of Aurélien Géron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized Example protobuf with two features: the serialized image (use tf.io.serialize_tensor() to serialize each image), and the label. Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first download the Fashion MNIST dataset. This is a collection of 60,000 images of fashion items, with size 28 x 28. The classes are the following:\n",
    "\n",
    "|Label|Description|\n",
    "|:---:|:---:|\n",
    "|0|T-shirt/top|\n",
    "|1|Trouser|\n",
    "|2|Pullover|\n",
    "|3|Dress|\n",
    "|4|Coat|\n",
    "|5|Sandal|\n",
    "|6|Shirt|\n",
    "|7|Sneaker|\n",
    "|8|Bag|\n",
    "|9|Ankle Boot|\n",
    "\n",
    "If you want to have more details on the dataset, please visit the [documentation of Keras](https://keras.io/api/datasets/fashion_mnist/#fashion-mnist-dataset-an-alternative-to-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = datasets.fashion_mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train, x_valid = train_test_split(x_train_full, test_size=0.2)\n",
    "y_train, y_valid = train_test_split(y_train_full, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data, we will create a dataset using the ```tf.data.Dataset.from_tensor_slices()``` method. We will only shuffle the training data since this is the data the model will use to be trained, therefore is the data we need to be independent and identically distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 12:31:39.522629: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-30 12:31:39.522743: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(len(x_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to save the datasets in different TFRecord files. We will save each record using 2 features: The serialized image and the label. To save them, we will use the ```Example``` protobuf implemented in TensorFlow. A protobuf (serialized protocol buffer) is a binary file developed by Google that is efficient, portable and extensible. TFRecord allows to save data in an efficient way, especially for binaries records with large amount of data. \n",
    "\n",
    "You can read more about the ```Example``` protobuf implemented by TensorFlow [here](https://www.tensorflow.org/api_docs/python/tf/train/Example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tfrecord(image, label, filepath):\n",
    "    \n",
    "    image = tf.io.serialize_tensor(image).numpy()\n",
    "    label = label.numpy()\n",
    "    \n",
    "    image_example = Example(\n",
    "        features = Features(\n",
    "            feature = {\n",
    "                'image' : Feature(bytes_list = BytesList(value = [image])),\n",
    "                'label' : Feature(int64_list = Int64List(value = [label]))\n",
    "    }))\n",
    "    \n",
    "    with tf.io.TFRecordWriter(filepath) as f:\n",
    "        f.write(image_example.SerializeToString())\n",
    "\n",
    "\n",
    "def save_dataset(dataset, data_type='train', n_files=15):\n",
    "    \n",
    "    folder_path = f'datasets/mnist_fashion/{data_type}_data'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    filepaths = [f'{folder_path}/{data_type}_{number_file}.tfrecord' for number_file in range(n_files)]\n",
    "    \n",
    "    for index, (image, label) in dataset.enumerate():\n",
    "        file_number = index % n_files\n",
    "        \n",
    "        filepath = f'{folder_path}/{data_type}_{file_number}.tfrecord'\n",
    "        \n",
    "        save_tfrecord(image, label, filepath)\n",
    "    \n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function will take an image, a label and the filepath for the current record. It will create a serialize tensor of the image. the ```numpy()``` method transforms the tensor to a single value that can be passed to the ```Example``` protobuf.\n",
    "\n",
    "The second function takes the dataset and enumerates the records in the dataset using the ```enumerate()``` method. This will return an index to determine the number of the file this record will be saved to. Using this index and the data type, the function creates the folder, the filepath list, and saves each record into a different TFRecord file. Finally returns the pattern of the filepath for the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = save_dataset(train_set, 'train')\n",
    "valid_filepath = save_dataset(valid_set, 'valid')\n",
    "test_filepath = save_dataset(test_set, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create an efficient dataset by loading the images and label from the TFRecord files. To do so, we will use the filepaths created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(serialized_image):\n",
    "    \n",
    "    feature_descriptions = {\n",
    "        'image' : tf.io.FixedLenFeature([], tf.string, default_value=b''),\n",
    "        'label' : tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(serialized_image,\n",
    "                                       feature_descriptions)\n",
    "    \n",
    "    image = tf.io.parse_tensor(example['image'], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=(28, 28))\n",
    "    \n",
    "    return image, example['label']\n",
    "\n",
    "def tfrecord_reader(filepaths, shuffle_buffer_size=None, batch_size=32):\n",
    "    \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    \n",
    "    return dataset.batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```tfrecord_reader``` takes the filepaths of each set, and loads them using the ```tf.data.TFRecordDataset()``` method. We allow multithreading by setting the ```num_parallel_reads``` parameter to ```tf.data.AUTOTUNE```. This will tune the parameter at runtime to be as efficient as possible.\n",
    "\n",
    "Then, we cache the content of the dataset to memory. The ```preprocessing()``` function is used with the ```map()``` method to load the records. The records are loaded in the ```preprocessing()``` function. It is important to use the ```tf.io.parse_tensor()``` to parse the image tensor to *uint8*, and then reshape the image. Again we allow the multithreading for the ```map()``` by setting the ```num_parallel_calls``` parameter to ```tf.data.AUTOTUNE```.\n",
    "\n",
    "Finally, we shuffle the dataset, batch it and prefetch to improve the performance. Once again, we use the ```tf.data.AUTOTUNE``` value for ```prefetch()``` to allow the value being automatically tuned by TensorFlow at runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tfrecord_reader(train_filepath)\n",
    "valid_set = tfrecord_reader(valid_filepath)\n",
    "test_set = tfrecord_reader(test_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the dataset, let's create a simple model. Let's use the ```keras.layers.Normalization()``` layer in order to standardize the input. In order to calculate the mean and standard deviation of this layer, we will need to call its ```adapt()``` method. To do so, we will need a sample, that will be parsed into a numpy array and passed to the normalization layer.\n",
    "\n",
    "Then we create a simple model, with a callback to save the logs for the Tensorboard visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 12:35:01.749590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-30 12:35:01.767240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-30 12:35:01.826163: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-01-30 12:35:01.826181: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-01-30 12:35:01.826195: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 12:35:02.093649: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - loss: 6.4226 - accuracy: 0.0667 - val_loss: 3.5848 - val_accuracy: 0.0667 - 913ms/epoch - 913ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 12:35:02.646071: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "1/1 - 0s - loss: 1.2993 - accuracy: 0.6000 - val_loss: 3.5553 - val_accuracy: 0.0667 - 140ms/epoch - 140ms/step\n",
      "Epoch 3/5\n",
      "1/1 - 0s - loss: 0.1674 - accuracy: 1.0000 - val_loss: 3.5862 - val_accuracy: 0.0667 - 85ms/epoch - 85ms/step\n",
      "Epoch 4/5\n",
      "1/1 - 0s - loss: 0.0463 - accuracy: 1.0000 - val_loss: 3.6069 - val_accuracy: 0.0667 - 78ms/epoch - 78ms/step\n",
      "Epoch 5/5\n",
      "1/1 - 0s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 3.6265 - val_accuracy: 0.0667 - 80ms/epoch - 80ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(15)\n",
    "np.random.seed(15)\n",
    "\n",
    "# Create the model using the custom layer created previously.\n",
    "\n",
    "sample_data = train_set.take(500).map(lambda image, label: image)\n",
    "sample_data = np.concatenate(list(sample_data.as_numpy_iterator()), axis=0).astype(np.float32)\n",
    "normalizer = layers.Normalization(input_shape=[28, 28])\n",
    "normalizer.adapt(sample_data)\n",
    "\n",
    "model = models.Sequential([\n",
    "    normalizer,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(250, activation='elu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model \n",
    "\n",
    "optimizer = optimizers.Nadam()\n",
    "\n",
    "model.compile(loss = losses.sparse_categorical_crossentropy,\n",
    "              optimizer = optimizer,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Create the callback for tensorboard\n",
    "\n",
    "logs_path = os.path.join(os.curdir, 'logs', 'run_' + datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "\n",
    "tensorboard_cb = callbacks.TensorBoard(\n",
    "    log_dir = logs_path,\n",
    "    histogram_freq=1,\n",
    "    profile_batch=10\n",
    ")\n",
    "\n",
    "list_cb = [tensorboard_cb]\n",
    "\n",
    "# Train the model\n",
    "history_model = model.fit(train_set,\n",
    "                          validation_data=valid_set,\n",
    "                          epochs=5,\n",
    "                          callbacks=list_cb,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is clearly overfitting, and more regularization is required. \n",
    "\n",
    "Then, we call the tensorboard to visualiza the performance of the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 255).\n",
       "Contents of stderr:\n",
       "E0130 12:32:04.440227 4305732992 program.py:298] TensorBoard could not bind to port 6006, it was already in use\n",
       "ERROR: TensorBoard could not bind to port 6006, it was already in use"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this exercise you will download a dataset, split it, create a tf.data.Dataset to load it and preprocess it efficiently, then build and train a binary classification model containing an Embedding layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Download the Large Movie Review Dataset, which contains 50,000 movies reviews from the Internet Movie Database. The data is organized in two directories, train and test, each containing a pos subdirectory with 12,500 positive reviews and a neg subdirectory with 12,500 negative reviews. Each review is stored in a separate text file. There are other files and folders (including preprocessed bag-of-words), but we will ignore them in this exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \n",
    "    return None\n",
    "\n",
    "def read_text_files(filepath):\n",
    "    \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    dataset = tf.keras.utils.text_dataset_from_directory(filepath)\n",
    "    for neg, pos in dataset:\n",
    "        print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['neg', 'pos']\n",
    "train_filepath = 'datasets/aclImdb/train'\n",
    "test_filepath = 'datasets/aclImdb/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/aclImdb/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mread_text_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_filepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mread_text_files\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text_files\u001b[39m(filepath):\n\u001b[1;32m      7\u001b[0m     AUTOTUNE \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE\n\u001b[0;32m----> 8\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m neg, pos \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(pos)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/preprocessing/text_dataset.py:140\u001b[0m, in \u001b[0;36mtext_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, batch_size, max_length, shuffle, seed, validation_split, subset, follow_links)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m   seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m file_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    151\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    152\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/books-zhEizXov-py3.9/lib/python3.9/site-packages/keras/preprocessing/dataset_utils.py:66\u001b[0m, in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m   subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 66\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m     68\u001b[0m       subdirs\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/aclImdb/train'"
     ]
    }
   ],
   "source": [
    "read_text_files(train_filepath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b5f867329b9bf7e45db95e42066174580d403eff48fd9a79312950ee94a58cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('Books-uCdQc7s-': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
