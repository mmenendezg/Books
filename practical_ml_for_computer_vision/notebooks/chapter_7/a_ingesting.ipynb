{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Ingesting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tensorflow version: {tf.version.VERSION}\")\n",
    "print(\n",
    "    f\"Built with GPU support? {'Yes!' if len(tf.config.list_logical_devices('GPU'))>0 else 'Noo!'}\"\n",
    ")\n",
    "print(f\"There are {len(tf.config.list_physical_devices('GPU'))} GPUs available.\")\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == \"\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "else:\n",
    "    print(f\"Found GPU at: {device_name}\")\n",
    "\n",
    "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"COMPRESSED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "IMG_HEIGHT = 448\n",
    "IMG_WIDTH = 448\n",
    "IMG_CHANNELS = 3\n",
    "CLASS_NAMES = \"daisy dandelion roses sunflowers tulips\".split()\n",
    "\n",
    "TRAIN_URL = \"gs://practical-ml-vision-book/flowers_tfr/train-0000[01]-*\"\n",
    "VALID_URL = \"gs://practical-ml-vision-book/flowers_tfr/valid-*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logdir():\n",
    "    run_id = time.strftime(\"run_%Y%m%d-%H%M%S\")\n",
    "    return os.path.join(\"..\", \"..\", \"reports\", \"logs\", \"chapter_7_ingesting\", run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Preprocessor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def read_from_tfr(self, proto):\n",
    "        feature_description = {\n",
    "            \"image\": tf.io.VarLenFeature(tf.float32),\n",
    "            \"shape\": tf.io.VarLenFeature(tf.int64),\n",
    "            \"label\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "            \"label_int\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "        }\n",
    "        record = tf.io.parse_single_example(proto, feature_description)\n",
    "        shape = tf.sparse.to_dense(record[\"shape\"])\n",
    "        image = tf.reshape(tf.sparse.to_dense(record[\"image\"]), shape)\n",
    "        label_int = record[\"label_int\"]\n",
    "        return image, label_int\n",
    "\n",
    "    def read_from_jpegfile(self, filename):\n",
    "        image = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        return image\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        return tf.image.resize_with_pad(image, IMG_HEIGHT, IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preproc_dataset_plain(pattern):\n",
    "    \"\"\"Creates the dataset without parallelizing the process\n",
    "\n",
    "    Args:\n",
    "        pattern (string): Pattern of the files in Cloud Storage\n",
    "\n",
    "    Returns:\n",
    "        trainds: Dataset with the images and the labels\n",
    "    \"\"\"\n",
    "    preproc = _Preprocessor()\n",
    "    trainds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            [file for file in tf.io.gfile.glob(pattern)], compression_type=\"GZIP\"\n",
    "        )\n",
    "        .map(preproc.read_from_tfr)\n",
    "        .map(lambda img, label: (preproc.preprocess(img), label))\n",
    "    )\n",
    "    return trainds\n",
    "\n",
    "\n",
    "def create_preproc_dataset_parallelmap(pattern):\n",
    "    \"\"\"Create the dataset from the TFRecord files, parallelizing the process\n",
    "\n",
    "    Args:\n",
    "        pattern (string): Pattern of the name of the files in Cloud Storage\n",
    "\n",
    "    Returns:\n",
    "        trainds: Dataset containing the images and the labels\n",
    "    \"\"\"\n",
    "    preproc = _Preprocessor()\n",
    "\n",
    "    def _preproc_image_label(img, label):\n",
    "        return (preproc.preprocess(img), label)\n",
    "\n",
    "    trainds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            [file for file in tf.io.gfile.glob(pattern)], compression_type=\"GZIP\"\n",
    "        )\n",
    "        .map(preproc.read_from_tfr, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_preproc_image_label, num_parallel_calls=AUTOTUNE)\n",
    "    )\n",
    "    return trainds\n",
    "\n",
    "\n",
    "def create_preproc_dataset_interleave(pattern, num_parallel=None):\n",
    "    \"\"\"Split the files into two halves and interleaves the datasets\n",
    "\n",
    "    Args:\n",
    "        pattern (string): Pattern of the files in the Cloud Storage\n",
    "        num_parallel (int, optional): Number of parallel calls when mapping the records. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        trainds: Dataset containing the images and the labels\n",
    "    \"\"\"\n",
    "    preproc = _Preprocessor()\n",
    "    files = [file for file in tf.io.gfile.glob(pattern)]\n",
    "    if len(files) > 1:\n",
    "        print(f\"Interleaving the reading of {len(files)} files.\")\n",
    "\n",
    "        def _create_half_ds(x):\n",
    "            if x == 0:\n",
    "                half = files[: len(files) // 2]\n",
    "            else:\n",
    "                half = files[len(files) // 2 :]\n",
    "            return tf.data.TFRecordDataset(half, compression_type=\"GZIP\")\n",
    "\n",
    "        trainds = tf.data.Dataset.range(2).interleave(\n",
    "            _create_half_ds, num_parallel_calls=AUTOTUNE\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        trainds = tf.data.TFRecordDataset(files, compression_type=\"GZIP\")\n",
    "\n",
    "    def _preproc_image_label(image, label):\n",
    "        return (preproc.preprocess(image), label)\n",
    "\n",
    "    trainds = trainds.map(preproc.read_from_tfr, num_parallel_calls=num_parallel).map(\n",
    "        _preproc_image_label, num_parallel_calls=num_parallel\n",
    "    )\n",
    "\n",
    "    return trainds\n",
    "\n",
    "\n",
    "def create_preproc_image(filename):\n",
    "    preproc = _Preprocessor()\n",
    "    img = preproc.read_from_jpegfile(filename)\n",
    "    return preproc.preprocess(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up the reading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_dataset(dataset, epochs):\n",
    "    lowest_mean = tf.constant(1.0)\n",
    "    for epoch in range(epochs):\n",
    "        thresh = np.random.uniform(0.3, 0.7)\n",
    "        count = 0\n",
    "        sum_so_far = tf.constant(0.0)\n",
    "        for (img, label) in dataset:\n",
    "            mean = tf.reduce_mean(tf.where(img > thresh, img, 0))\n",
    "            sum_so_far = sum_so_far + mean\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "        mean = sum_so_far / count\n",
    "        print(mean)\n",
    "        if mean < lowest_mean:\n",
    "            lowest_mean = mean\n",
    "\n",
    "    return lowest_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_preproc_dataset_plain(TRAIN_URL)\n",
    "loop_through_dataset(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_preproc_dataset_parallelmap(TRAIN_URL)\n",
    "loop_through_dataset(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "dataset = create_preproc_dataset_interleave(TRAIN_URL, num_parallel=None)\n",
    "loop_through_dataset(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_preproc_dataset_interleave(TRAIN_URL, num_parallel=AUTOTUNE)\n",
    "loop_through_dataset(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_model(dataset, epochs):\n",
    "    model = Sequential([\n",
    "        layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "        layers.Dense(len(CLASS_NAMES), activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_preproc_dataset_plain(TRAIN_URL).batch(1)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_preproc_dataset_parallelmap(TRAIN_URL).batch(1)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_preproc_dataset_interleave(TRAIN_URL, num_parallel=None).batch(1)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_preproc_dataset_interleave(TRAIN_URL, num_parallel=AUTOTUNE).batch(1)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up the handling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prepoc_dataset(pattern):\n",
    "    return create_preproc_dataset_interleave(pattern, num_parallel=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_prepoc_dataset(TRAIN_URL).prefetch(AUTOTUNE).batch(1)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_prepoc_dataset(TRAIN_URL).prefetch(AUTOTUNE).batch(8)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_prepoc_dataset(TRAIN_URL).prefetch(AUTOTUNE).batch(16)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_prepoc_dataset(TRAIN_URL).prefetch(AUTOTUNE).batch(32)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = create_prepoc_dataset(TRAIN_URL).cache().prefetch(AUTOTUNE).batch(32)\n",
    "train_simple_model(dataset, NUM_EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b20fb8559386147dc77cba9f7518a8c175fc982b8c10bebe842520e16b3ac5d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
