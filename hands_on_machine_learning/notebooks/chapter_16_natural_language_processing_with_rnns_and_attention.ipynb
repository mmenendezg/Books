{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    utils,\n",
    "    preprocessing,\n",
    "    models,\n",
    "    layers,\n",
    "    callbacks,\n",
    "    datasets\n",
    ")\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Shakespearean Text Using a Character RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = 'https://homl.info/shakespeare' # shortcut URL\n",
    "filepath = utils.get_file('shakespeare.txt', shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tokenize the text by characters\n",
    "tokenizer = preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b e v e r l y   a n d   c h r i s t a']\n"
     ]
    }
   ],
   "source": [
    "# Let's see an example of how to tokenize\n",
    "sequence = tokenizer.texts_to_sequences(['Beverly and Christa'])\n",
    "new_phrase = tokenizer.sequences_to_texts(sequence)\n",
    "print(new_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "dataset_size = tokenizer.document_count\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 20:18:25.515856: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-04 20:18:25.516036: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Let's separate the data into training, validation and test\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chopping the Sequential Dataset into Multiple Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's chop the sequential dataset\n",
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
    "\n",
    "# Flattening the dataset \n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the categorical feature as one-hot enconding\n",
    "dataset = dataset.map(lambda x_b, y_b: (tf.one_hot(x_b, depth=max_id), y_b))\n",
    "dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building adn Training the Char-RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 20:18:26.062622: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-04 20:18:27.325265: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-04 20:18:28.222278: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-04 20:18:28.377301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-04 20:18:28.567077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-04 20:18:28.831567: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4016/4016 [==============================] - 238s 59ms/step - loss: 3.0270\n",
      "Epoch 2/20\n",
      "4016/4016 [==============================] - 233s 58ms/step - loss: 2.7952\n",
      "Epoch 3/20\n",
      "4016/4016 [==============================] - 229s 57ms/step - loss: 2.6617\n",
      "Epoch 4/20\n",
      "4016/4016 [==============================] - 231s 57ms/step - loss: 2.6535\n",
      "Epoch 5/20\n",
      "4016/4016 [==============================] - 231s 57ms/step - loss: 2.5963\n",
      "Epoch 6/20\n",
      "4016/4016 [==============================] - 234s 58ms/step - loss: 2.6655\n",
      "Epoch 7/20\n",
      "4016/4016 [==============================] - 237s 59ms/step - loss: 2.6640\n",
      "Epoch 8/20\n",
      "4016/4016 [==============================] - 236s 59ms/step - loss: 2.6573\n",
      "Epoch 9/20\n",
      "4016/4016 [==============================] - 230s 57ms/step - loss: 2.6703\n",
      "Epoch 10/20\n",
      "4016/4016 [==============================] - 227s 56ms/step - loss: 2.6815\n",
      "Epoch 11/20\n",
      "4016/4016 [==============================] - 231s 57ms/step - loss: 2.6844\n",
      "Epoch 12/20\n",
      "4016/4016 [==============================] - 236s 59ms/step - loss: 2.6521\n",
      "Epoch 13/20\n",
      "4016/4016 [==============================] - 236s 59ms/step - loss: 2.6326\n",
      "Epoch 14/20\n",
      "4016/4016 [==============================] - 237s 59ms/step - loss: 2.6278\n",
      "Epoch 15/20\n",
      "4016/4016 [==============================] - 240s 59ms/step - loss: 2.6017\n",
      "Epoch 16/20\n",
      "4016/4016 [==============================] - 234s 58ms/step - loss: 2.5700\n",
      "Epoch 17/20\n",
      "4016/4016 [==============================] - 230s 57ms/step - loss: 2.5721\n",
      "Epoch 18/20\n",
      "4016/4016 [==============================] - 232s 58ms/step - loss: 2.5662\n",
      "Epoch 19/20\n",
      "4016/4016 [==============================] - 235s 58ms/step - loss: 2.5708\n",
      "Epoch 20/20\n",
      "4016/4016 [==============================] - 236s 59ms/step - loss: 2.5966\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2),\n",
    "    layers.GRU(128, return_sequences=True, dropout=0.2),\n",
    "    layers.Dense(max_id, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "\n",
    "history = model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Char-RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    x = np.array(tokenizer.texts_to_sequences(texts))\n",
    "    return tf.one_hot(x, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "x_new = preprocess(['nice to meet yo'])\n",
    "y_pred = np.argmax(model.predict(x_new), axis=-1)\n",
    "char_pred = tokenizer.sequences_to_texts(y_pred + 1)[0][-1]\n",
    "print(char_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Fake Shakespearean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    x_new = preprocess([text])\n",
    "    y_proba = model.predict(x_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tueer             \n",
      " h                              \n"
     ]
    }
   ],
   "source": [
    "print(complete_text('t', temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w al,lli m\n",
      "  \n",
      "; ri tn groe'h,e.tuwolli ose n\n",
      "e ' ts\n"
     ]
    }
   ],
   "source": [
    "print(complete_text('w', temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w fee,ee\n",
      ".sx,o?nsn dose\n",
      "pvordu! sccclr\n",
      "  t:uduanwlr\n"
     ]
    }
   ],
   "source": [
    "print(complete_text('w', temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for stateful RNN\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]), num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.map(lambda x_b, y_b: (tf.one_hot(x_b, depth=max_id), y_b), num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateful_model = models.Sequential([\n",
    "    layers.GRU(128, return_sequences=True, stateful=True, dropout=0.2,\n",
    "               batch_input_shape=[32, None, max_id]),\n",
    "    layers.GRU(128, return_sequences=True, stateful=True, dropout=0.2),\n",
    "    layers.TimeDistributed(layers.Dense(max_id, activation='softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to reset the states at the end of each epoch\n",
    "class ResetStatesCallback(callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "# model.fit(dataset, epochs=50, callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n",
      "17473536/17464789 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the IMDb reviews dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data()\n",
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode the message \n",
    "word_index = datasets.imdb.get_word_index()\n",
    "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
    "\n",
    "for id_, token in enumerate(('<pad>', '<sos>', '<unk>')):\n",
    "    id_to_word[id_] = token\n",
    "    \n",
    "' '.join([id_to_word[id_] for id_ in x_train[0][:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_datsets, info = tfds.load('imdb_reviews', as_supervised=True, with_info=True)\n",
    "train_size = info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function for the data\n",
    "def preprocess(x_batch, y_batch):\n",
    "    x_batch = tf.strings.substr(x_batch, 0, 300)\n",
    "    x_batch = tf.strings.regex_replace(x_batch, b'<br\\\\s*/?>', b' ')\n",
    "    x_batch = tf.strings.regex_replace(x_batch, b\"[^a-zA-Z']\", b' ')\n",
    "    x_batch = tf.strings.split(x_batch)\n",
    "    return x_batch.to_tensor(default_value=b'<pad>'), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count the occurrences of the words in the dataset \n",
    "vocabulary = Counter()\n",
    "for x_batch, y_batch in imdb_datsets['train'].batch(32).map(preprocess):\n",
    "    for review in x_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the three most common words\n",
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [\n",
    "    word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's replace the words for their ID (index in the vocabulary)\n",
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[   22,    12,    11, 10252,     6,   102,  1020,    10]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the previous table to look up for some words\n",
    "table.lookup(tf.constant([b\"This movie was bullshit, I don't buy it\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that encodes the words using the table created\n",
    "def encode_words(x_batch, y_batch):\n",
    "    return table.lookup(x_batch), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = imdb_datsets['train'].batch(32).map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_set = train_set.map(encode_words, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 14:19:13.434790: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-07 14:19:13.749624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-07 14:19:13.887233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-07 14:19:14.588084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-07 14:19:14.872878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 38s 45ms/step - loss: 0.6936 - accuracy: 0.4984\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.6937 - accuracy: 0.5020\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.6564 - accuracy: 0.6043\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.5224 - accuracy: 0.7414\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4200 - accuracy: 0.8085\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "                     input_shape=[None]),\n",
    "    layers.GRU(128, return_sequences=True),\n",
    "    layers.GRU(128),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a similar model with masking\n",
    "k = tf.keras.backend\n",
    "inputs = layers.Input(shape=[None])\n",
    "mask = layers.Lambda(lambda inputs: k.not_equal(inputs, 0))(inputs)\n",
    "z = layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
    "z = layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = layers.GRU(128)(z, mask=mask)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(z)\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 15:59:09.168002: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1',\n",
    "                   dtype=tf.string, input_shape=[], output_shape=[50]),\n",
    "    layers.Dense(128, activation='elu', kernel_initializer='he_normal'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/782 [..............................] - ETA: 4:28 - loss: 0.6772 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 16:02:59.668102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5443 - accuracy: 0.7260\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5195 - accuracy: 0.7428\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5165 - accuracy: 0.7450\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5144 - accuracy: 0.7475\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5126 - accuracy: 0.7488\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5111 - accuracy: 0.7494\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5098 - accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5087 - accuracy: 0.7509\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5076 - accuracy: 0.7518\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.5067 - accuracy: 0.7527\n"
     ]
    }
   ],
   "source": [
    "# Let's train the same IMDb dataset on this new model\n",
    "imdb_datsets, info = tfds.load('imdb_reviews', as_supervised=True, with_info=True)\n",
    "train_size = info.splits['train'].num_examples\n",
    "batch_size = 32\n",
    "train_set = imdb_datsets['train'].batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "history = model.fit(train_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9465219]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = tf.constant(['God Loves us'])\n",
    "pred = model.predict(phrase)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Encoder-Decoder Network for Neural Machine Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = layers.Input(shape=[None], dtype=tf.int32)\n",
    "decoder_inputs = layers.Input(shape=[None], dtype=tf.int32)\n",
    "sequence_length = layers.Input(shape=[], dtype=tf.int32)\n",
    "\n",
    "embeddings = layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "\n",
    "encoder = layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = layers.LSTMCell(512)\n",
    "output_layer = layers.Dense(vocab_size)\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)\n",
    "\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state,\n",
    "    sequence_length=sequence_length)\n",
    "y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs, sequence_length],\n",
    "                       outputs=[y_proba])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.wrappers.Bidirectional at 0x360576970>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To create a bidirectional recurrent layer\n",
    "layers.Bidirectional(layers.GRU(10, return_sequences=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement beam search\n",
    "beam_width = 10\n",
    "decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n",
    "    cell=decoder_cell, beam_width=beam_width, output_layer=output_layer)\n",
    "decoder_initial_state = tfa.seq2seq.beam_search_decoder.tile_batch(\n",
    "    encoder_state, multiplier=beam_width\n",
    ")\n",
    "outputs, _, _ = decoder(\n",
    "    decoder_embeddings #, start_tokens=start_tokens, end_token=end_token,\n",
    "    initial_state=decoder_initial_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent Innovations in Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6ba1b7cf6e8418139948d4f5b35e26443252c5696a8a4a7bc6c27d254786872"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('books-zhEizXov-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
